% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stream.R
\name{stream}
\alias{stream}
\alias{stream_chunk_write}
\alias{stream_window_features}
\title{stream}
\usage{
stream(
  streams = c("email_stream", "ticket_stream", "contribution_stream",
    "membership_stream", "ticket_future_stream", "address_stream"),
  fill_match =
    "^(email|ticket|contribution|membership|ticket|address).+(amt|level|count|max|min|last)",
  window_match = "^(email|ticket|contribution|membership|ticket|address).+(count|amt)$",
  chunk_size = 1e+06,
  rebuild = FALSE,
  incremental = !rebuild,
  windows = lapply(c(1, 7, 30, 90, 365), lubridate::period, units = "day"),
  ...
)

stream_chunk_write(
  stream,
  fill_cols = setdiff(colnames(stream), c(by, "timestamp")),
  window_cols = fill_cols,
  since = as_datetime(min(stream$timestamp)),
  by = "group_customer_no",
  incremental = TRUE,
  ...
)

stream_window_features(
  stream,
  window_cols = setdiff(colnames(stream), c(by, "timestamp")),
  windows = NULL,
  by = "group_customer_no",
  ...
)
}
\arguments{
\item{streams}{\link{character} vector of streams to combine}

\item{fill_match}{\href{1}{character} regular expression to use when matching columns to fill down}

\item{window_match}{\href{1}{character} regular expression to use when matching columns to window}

\item{chunk_size}{\href{1}{integer} number of rows to include in each partition of the dataset}

\item{rebuild}{\href{1}{logical} whether or not to rebuild the whole dataset (\code{TRUE}) or just append to the end of it (\code{FALSE})}

\item{incremental}{\href{1}{logical} whether or not to update the cache incrementally. Can require huge amounts of memory (approximately double the total dataset size to be appended).}

\item{windows}{\link[lubridate:period]{lubridate::period} vector that determines the offsets used when constructing the windowed features.}

\item{...}{not used}

\item{stream}{\link{data.table} data to process and write}

\item{fill_cols}{\link{character} columns to fill down}

\item{window_cols}{\link{character} columns to window}

\item{since}{\link{POSIXct} only the data with timestamps greater than or equal to \code{since} will be written}

\item{by}{\href{1}{character} column name to group by for filling down and windowing}
}
\value{
stream dataset as an \link[arrow:Table-class]{arrow::Table}
}
\description{
Combine all streams named in \code{streams} into a single dataset, filling down columns matched by \code{fill_match} and
creating windowed features using \code{windows} as offsets for columns matched by \code{window_match}.
The full dataset is rebuilt if \code{rebuild} is \code{TRUE} (default: \code{FALSE}), and data is appended to the
existing cache if \code{incremental} is \code{TRUE} (default: \code{TRUE})
}
\section{Functions}{
\itemize{
\item \code{stream_chunk_write()}: Fill down cols in \code{stream_cols} and add windowed features to \code{stream} for timestamps after \code{since}

\item \code{stream_window_features()}: construct windowed features for columns in \code{stream_cols}, using \code{windows},
a list of \link[lubridate:period]{lubridate::period}s as offsets, and grouped by \code{by}

}}
